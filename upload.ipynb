{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.conda/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "base_model_name = \"./model/Qwen3-0.6B\"\n",
    "lora_path = \"./lora_output/checkpoint-702\"\n",
    "\n",
    "# 1. 加载基础模型\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name).to(device)\n",
    "\n",
    "# 2. 加载 LoRA\n",
    "lora_model = PeftModel.from_pretrained(base_model, lora_path).to(device)\n",
    "\n",
    "# 3. 合并 LoRA 到 base_model\n",
    "lora_model.merge_and_unload()  # LoRA 权重直接写入 base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "指令: 你爸爸是谁？\n",
      "回答: 我是甄嬛，我父亲是大理寺少卿甄远道。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"指令: 你爸爸是谁？\\n回答:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = base_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen0.6B_lora_merged/tokenizer_config.json',\n",
       " './qwen0.6B_lora_merged/special_tokens_map.json',\n",
       " './qwen0.6B_lora_merged/chat_template.jinja',\n",
       " './qwen0.6B_lora_merged/vocab.json',\n",
       " './qwen0.6B_lora_merged/merges.txt',\n",
       " './qwen0.6B_lora_merged/added_tokens.json',\n",
       " './qwen0.6B_lora_merged/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model_dir = \"./qwen0.6B_lora_merged\"\n",
    "base_model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ms-b4990507-632e-49f8-9ec8-70461fa8b180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TJaEYBjeJz_vPFugsikN',\n",
       " <RequestsCookieJar[Cookie(version=0, name='acw_tc', value='0b62600617588128674432402e211bc1a4a1d9f41fa3116edba11eb2e5e685', port=None, port_specified=False, domain='www.modelscope.cn', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=1758814667, discard=False, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), Cookie(version=0, name='csrf_session', value='MTc1ODgxMjg2N3xEWDhFQVFMX2dBQUJFQUVRQUFBeV80QUFBUVp6ZEhKcGJtY01DZ0FJWTNOeVpsTmhiSFFHYzNSeWFXNW5EQklBRURFMlNWVmlNbEEwY21GbWJVMXhNbEE9fI4w6Asl3i_f53V_U7yRXcvVkFPRf5K4zZf7ZxK0vOBv', port=None, port_specified=False, domain='www.modelscope.cn', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=1761404867, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False), Cookie(version=0, name='csrf_token', value='EISUcQMsnVbcY869rB1iKMpj4Cw%3D', port=None, port_specified=False, domain='www.modelscope.cn', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=1761404867, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False), Cookie(version=0, name='m_session_id', value='ms-b4990507-632e-49f8-9ec8-70461fa8b180', port=None, port_specified=False, domain='www.modelscope.cn', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=1761404867, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False)]>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.hub.api import HubApi\n",
    "\n",
    "YOUR_ACCESS_TOKEN = 'ms-b4990507-632e-49f8-9ec8-70461fa8b180'\n",
    "api = HubApi()\n",
    "api.login(YOUR_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.modelscope.cn/models/nev8rz/huanhuanchat_base_qwen3_0_6B'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.hub.constants import Licenses, ModelVisibility\n",
    "\n",
    "owner_name = 'nev8rz'\n",
    "model_name = 'huanhuanchat_base_qwen3_0_6B'\n",
    "model_id = f\"{owner_name}/{model_name}\"\n",
    "\n",
    "api.create_model(\n",
    "    model_id,\n",
    "    visibility=ModelVisibility.PUBLIC,\n",
    "    license=Licenses.APACHE_V2,\n",
    "    chinese_name=\"嬛嬛\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 23:11:36,778 - modelscope - INFO - Preparing files to upload ...\n",
      "2025-09-25 23:11:36,782 - modelscope - INFO - Prepared 10 files for upload.\n",
      "2025-09-25 23:11:36,782 - modelscope - INFO - Checking 10 files to upload ...\n",
      "2025-09-25 23:11:36,966 - modelscope - WARNING - Repo nev8rz/huanhuanchat_base_qwen3_0_6B already exists, got repo url: https://www.modelscope.cn/models/nev8rz/huanhuanchat_base_qwen3_0_6B\n",
      "[Validating Hash for model.safetensors]: 100%|██████████| 2.38G/2.38G [00:32<00:00, 72.5MB/s]\n",
      "[Uploading model.safetensors]: 100%|██████████| 2.38G/2.38G [00:30<00:00, 79.5MB/s]\n",
      "Processing 10 items: 100%|██████████| 10.0/10.0 [01:03<00:00, 6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committing 10 files in 1 batch(es) of size 512.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Committing batches] :   0%|          | 0/1 [00:00<?, ?it/s]2025-09-25 23:12:41,445 - modelscope - INFO - Commit succeeded: https://www.modelscope.cn/api/v1/repos/models/nev8rz/huanhuanchat_base_qwen3_0_6B/commit/master\n",
      "[Committing batches] : 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://www.modelscope.cn/api/v1/repos/models/nev8rz/huanhuanchat_base_qwen3_0_6B/commit/master', commit_message='嬛嬛 来啦 (batch 1/1)', commit_description='Uploading files', oid='')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_folder(\n",
    "    repo_id=f\"{owner_name}/{model_name}\",\n",
    "    folder_path='./qwen0.6B_lora_merged/',\n",
    "    commit_message='嬛嬛 来啦',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
