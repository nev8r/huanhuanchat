{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/root/huanhuanchat/.venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29b04d57304b2786e5e06311d56127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/huanhuanchat/.venv/lib/python3.11/site-packages/accelerate/utils/modeling.py:1582: UserWarning: Current model requires 256 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = './model/qwen2p5_7b'\n",
    "lora_path = './output/qwen2p5_7b/checkpoint-702' # 这里改称你的 lora 输出对应 checkpoint 地址\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\",torch_dtype=torch.bfloat16, trust_remote_code=True).eval()\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "model.merge_and_unload()  # LoRA 权重直接写入 base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen2.5_7B_lora_merged/tokenizer_config.json',\n",
       " './qwen2.5_7B_lora_merged/special_tokens_map.json',\n",
       " './qwen2.5_7B_lora_merged/chat_template.jinja',\n",
       " './qwen2.5_7B_lora_merged/vocab.json',\n",
       " './qwen2.5_7B_lora_merged/merges.txt',\n",
       " './qwen2.5_7B_lora_merged/added_tokens.json',\n",
       " './qwen2.5_7B_lora_merged/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model_dir = \"./qwen2.5_7B_lora_merged\"\n",
    "model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.hub.api import HubApi\n",
    "\n",
    "api = HubApi()\n",
    "api.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.modelscope.cn/models/nev8rz/huanhuanchat_base_qwen2.5_7B'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.hub.constants import Licenses, ModelVisibility\n",
    "\n",
    "owner_name = 'nev8rz'\n",
    "model_name = 'huanhuanchat_base_qwen2.5_7B'\n",
    "model_id = f\"{owner_name}/{model_name}\"\n",
    "\n",
    "api.create_model(\n",
    "    model_id,\n",
    "    visibility=ModelVisibility.PUBLIC,\n",
    "    license=Licenses.APACHE_V2,\n",
    "    chinese_name=\"嬛嬛\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 22:46:28,257 - modelscope - INFO - Preparing files to upload ...\n",
      "2025-09-26 22:46:28,270 - modelscope - INFO - Prepared 10 files for upload.\n",
      "2025-09-26 22:46:28,270 - modelscope - INFO - Checking 10 files to upload ...\n",
      "2025-09-26 22:46:28,508 - modelscope - WARNING - Repo nev8rz/huanhuanchat_base_qwen2.5_7B already exists, got repo url: https://www.modelscope.cn/models/nev8rz/huanhuanchat_base_qwen2.5_7B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e67f36ec744fcda634b6fa0ec6b532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 10 items:   0%|          | 0.00/10.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committing 10 files in 1 batch(es) of size 512.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe53ee037b14674a7f532983e012f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Committing batches] :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 22:46:31,286 - modelscope - INFO - Commit succeeded: https://www.modelscope.cn/api/v1/repos/models/nev8rz/huanhuanchat_base_qwen2.5_7B/commit/master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://www.modelscope.cn/api/v1/repos/models/nev8rz/huanhuanchat_base_qwen2.5_7B/commit/master', commit_message='聪明一点的嬛嬛 (batch 1/1)', commit_description='Uploading files', oid='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_folder(\n",
    "    repo_id=f\"{owner_name}/{model_name}\",\n",
    "    folder_path='./qwen2.5_7B_lora_merged/',\n",
    "    commit_message='聪明一点的嬛嬛',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
